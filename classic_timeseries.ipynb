{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa5963-160f-42bb-af0b-d2b6bcc1a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae918f81-3f8b-4fa6-bbd7-d14fe5b767c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138c3a0-6831-4e9d-bbac-6a16108daca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# For time series analysis\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# For modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f9054-a705-40aa-b139-4a54f52c3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up visualization\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27894568-bffb-4afb-b7da-03df610d2cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and prepare the data\n",
    "# Create DataFrame\n",
    "df = pd.read_csv(os.path.join('backend', 'data', 'tqbr', 'SBER.csv'))\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set Date as index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1850202-1ecc-4f49-b38c-9c95639a5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Visualize the time series\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(df.index, df['Close'], label='Close Price')\n",
    "plt.title('Stock Close Price Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609daa62-4791-4d77-bb04-61068b5db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Check for stationarity\n",
    "def test_stationarity(timeseries):\n",
    "    # Perform Dickey-Fuller test\n",
    "    result = adfuller(timeseries, autolag='AIC')\n",
    "    print('ADF Statistic:', result[0])\n",
    "    print('p-value:', result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"The series is stationary\")\n",
    "    else:\n",
    "        print(\"The series is non-stationary\")\n",
    "\n",
    "print(\"Stationarity test for Close price:\")\n",
    "test_stationarity(df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6db7b-4644-4af7-9327-a97c46b43459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create lagged features for regression models\n",
    "def create_lagged_features(data, target_col, lags):\n",
    "    df_lagged = data.copy()\n",
    "    for lag in range(1, lags + 1):\n",
    "        df_lagged[f'{target_col}_lag_{lag}'] = df_lagged[target_col].shift(lag)\n",
    "    return df_lagged\n",
    "\n",
    "# Create lagged features (using last 5 days)\n",
    "lags = 5\n",
    "df_lagged = create_lagged_features(df, 'Close', lags)\n",
    "\n",
    "# Add additional features\n",
    "df_lagged['MA_5'] = df_lagged['Close'].shift(1).rolling(window=5).mean()\n",
    "df_lagged['MA_10'] = df_lagged['Close'].shift(1).rolling(window=10).mean()\n",
    "df_lagged['Daily_Return'] = df_lagged['Close'].shift(1).pct_change() * 100\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df_lagged.dropna(inplace=True)\n",
    "\n",
    "print(\"Data with lagged features:\")\n",
    "print(df_lagged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa87e3-64ba-4a7f-af6b-8539c20b59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Split data for forecasting\n",
    "# For time series, we should use chronological split\n",
    "train_size = int(len(df_lagged) * 0.8)\n",
    "train_data = df_lagged.iloc[:train_size]\n",
    "test_data = df_lagged.iloc[train_size:]\n",
    "\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710c479-fbf8-4907-9f68-23f672e5aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Linear Regression with lagged features\n",
    "# Prepare features for linear regression\n",
    "lag_features = [f'Close_lag_{i}' for i in range(1, lags + 1)]\n",
    "additional_features = ['MA_5', 'MA_10', 'Daily_Return']\n",
    "additional_features = []\n",
    "X_train_lr = train_data[lag_features + additional_features]\n",
    "y_train_lr = train_data['Close']\n",
    "X_test_lr = test_data[lag_features + additional_features]\n",
    "y_test_lr = test_data['Close']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_lr_scaled = scaler.fit_transform(X_train_lr)\n",
    "X_test_lr_scaled = scaler.transform(X_test_lr)\n",
    "\n",
    "# Train model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_lr_scaled, y_train_lr)\n",
    "\n",
    "# Make predictions\n",
    "lr_pred = lr_model.predict(X_test_lr_scaled)\n",
    "\n",
    "# Evaluate\n",
    "lr_mse = mean_squared_error(y_test_lr, lr_pred)\n",
    "lr_mae = mean_absolute_error(y_test_lr, lr_pred)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "\n",
    "print(\"Linear Regression Model:\")\n",
    "print(f\"Mean Squared Error: {lr_mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {lr_mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {lr_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ac210-7056-4d9f-9801-2a8240caf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Random Forest with lagged features\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_lr, y_train_lr)\n",
    "\n",
    "# Make predictions\n",
    "rf_pred = rf_model.predict(X_test_lr)\n",
    "\n",
    "# Evaluate\n",
    "rf_mse = mean_squared_error(y_test_lr, rf_pred)\n",
    "rf_mae = mean_absolute_error(y_test_lr, rf_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "\n",
    "print(\"\\nRandom Forest Model:\")\n",
    "print(f\"Mean Squared Error: {rf_mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {rf_mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rf_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eab38e-f6e3-4dfc-b38b-d68e70462854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: ARIMA Model\n",
    "# Prepare data for ARIMA (only use the close price)\n",
    "arima_train = train_data['Close']\n",
    "arima_test = test_data['Close']\n",
    "\n",
    "# Fit ARIMA model\n",
    "# Using (5,1,0) as a starting point - can be optimized with grid search\n",
    "arima_model = ARIMA(arima_train, order=(5, 1, 0))\n",
    "arima_model_fit = arima_model.fit()\n",
    "\n",
    "# Make predictions\n",
    "arima_pred = arima_model_fit.forecast(steps=len(arima_test))\n",
    "\n",
    "# Evaluate\n",
    "arima_mse = mean_squared_error(arima_test, arima_pred)\n",
    "arima_mae = mean_absolute_error(arima_test, arima_pred)\n",
    "arima_rmse = np.sqrt(arima_mse)\n",
    "\n",
    "print(\"\\nARIMA Model:\")\n",
    "print(f\"Mean Squared Error: {arima_mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {arima_mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {arima_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592d00f-6777-4219-ab06-6d3e5864c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Compare model predictions\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(test_data.index, y_test_lr, label='Actual', linewidth=2)\n",
    "plt.plot(test_data.index, lr_pred, label='Linear Regression', alpha=0.7)\n",
    "plt.plot(test_data.index, rf_pred, label='Random Forest', alpha=0.7)\n",
    "plt.plot(test_data.index, arima_pred, label='ARIMA', alpha=0.7)\n",
    "plt.title('Stock Price Forecasting: Model Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943a14b-79f2-4f1b-99e7-4a68811be857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Model performance comparison\n",
    "models = ['Linear Regression', 'Random Forest', 'ARIMA']\n",
    "mse_values = [lr_mse, rf_mse, arima_mse]\n",
    "mae_values = [lr_mae, rf_mae, arima_mae]\n",
    "rmse_values = [lr_rmse, rf_rmse, arima_rmse]\n",
    "\n",
    "# Create a comparison dataframe\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'MSE': mse_values,\n",
    "    'MAE': mae_values,\n",
    "    'RMSE': rmse_values\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(performance_df)\n",
    "\n",
    "# Visualize performance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.barplot(x='Model', y='MSE', data=performance_df, ax=axes[0])\n",
    "axes[0].set_title('Mean Squared Error')\n",
    "sns.barplot(x='Model', y='MAE', data=performance_df, ax=axes[1])\n",
    "axes[1].set_title('Mean Absolute Error')\n",
    "sns.barplot(x='Model', y='RMSE', data=performance_df, ax=axes[2])\n",
    "axes[2].set_title('Root Mean Squared Error')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e37995-9240-4ca3-8d61-55669d9c4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Feature importance for Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': lag_features + additional_features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64c2a7-81ef-4bb8-beee-23ff54dee7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Time series decomposition\n",
    "decomposition = seasonal_decompose(df['Close'], model='additive', period=30)  # Assuming monthly seasonality\n",
    "fig = decomposition.plot()\n",
    "fig.set_size_inches(14, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfec395-4186-4f33-b6e9-03e05b10fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: ACF and PACF plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "plot_acf(df['Close'], lags=30, ax=axes[0])\n",
    "plot_pacf(df['Close'], lags=30, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32850e06-a9ca-4cf4-ab85-738e1e8aa9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Understanding and Handling Non-Stationarity\n",
    "\n",
    "# First, let's visualize why the series is non-stationary\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df.index, df['Close'])\n",
    "plt.title('Original Non-Stationary Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# Calculate and plot the rolling mean and standard deviation\n",
    "rolling_mean = df['Close'].rolling(window=30).mean()\n",
    "rolling_std = df['Close'].rolling(window=30).std()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df.index, df['Close'], label='Original')\n",
    "plt.plot(df.index, rolling_mean, label='Rolling Mean')\n",
    "plt.plot(df.index, rolling_std, label='Rolling Std')\n",
    "plt.title('Rolling Statistics')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6ff87-b032-4d61-8148-d201fdc415d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Transform to Stationary Series\n",
    "\n",
    "# Method 1: First differencing (most common for stock prices)\n",
    "df['Close_diff'] = df['Close'].diff()\n",
    "df['Close_diff'].dropna(inplace=True)\n",
    "\n",
    "# Test stationarity of the differenced series\n",
    "print(\"Stationarity test for first difference:\")\n",
    "test_stationarity(df['Close_diff'].dropna())\n",
    "\n",
    "# Method 2: Log transformation + differencing\n",
    "df['Close_log'] = np.log(df['Close'])\n",
    "df['Close_log_diff'] = df['Close_log'].diff()\n",
    "df['Close_log_diff'].dropna(inplace=True)\n",
    "\n",
    "print(\"\\nStationarity test for log difference:\")\n",
    "test_stationarity(df['Close_log_diff'].dropna())\n",
    "\n",
    "# Visualize the transformed series\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df.index, df['Close_diff'])\n",
    "plt.title('First Difference')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price Difference')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df.index, df['Close_log_diff'])\n",
    "plt.title('Log Difference')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Difference')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9d2ec-f896-42e8-b20e-07bdc202e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Update ARIMA Model with Differencing\n",
    "\n",
    "# The 'd' parameter in ARIMA(p,d,q) handles differencing\n",
    "# Since we found the series is non-stationary, we need d >= 1\n",
    "# Let's try ARIMA(5,1,0) with the original data (d=1 for first differencing)\n",
    "arima_train = train_data['Close']\n",
    "arima_test = test_data['Close']\n",
    "\n",
    "# Fit ARIMA model with differencing\n",
    "arima_model = ARIMA(arima_train, order=(5, 1, 0))\n",
    "arima_model_fit = arima_model.fit()\n",
    "\n",
    "# Make predictions\n",
    "arima_pred = arima_model_fit.forecast(steps=len(arima_test))\n",
    "\n",
    "# Evaluate\n",
    "arima_mse = mean_squared_error(arima_test, arima_pred)\n",
    "arima_mae = mean_absolute_error(arima_test, arima_pred)\n",
    "arima_rmse = np.sqrt(arima_mse)\n",
    "\n",
    "print(\"ARIMA Model with Differencing:\")\n",
    "print(f\"Mean Squared Error: {arima_mse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {arima_mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {arima_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af437647-480f-430b-9213-3b78ee69c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Work with Returns Instead of Prices\n",
    "\n",
    "# Calculate daily returns (percentage change)\n",
    "df['Daily_Return'] = df['Close'].pct_change() * 100\n",
    "df['Daily_Return'].dropna(inplace=True)\n",
    "\n",
    "# Test stationarity of returns\n",
    "print(\"\\nStationarity test for daily returns:\")\n",
    "test_stationarity(df['Daily_Return'].dropna())\n",
    "\n",
    "# Visualize returns\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df.index, df['Daily_Return'])\n",
    "plt.title('Daily Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Return (%)')\n",
    "\n",
    "# Histogram of returns\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['Daily_Return'].dropna(), bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Daily Returns')\n",
    "plt.xlabel('Return (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008bcdc4-dc4f-4ab9-9a6f-8473be8d40d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Update Models to Work with Returns\n",
    "\n",
    "# Create lagged features for returns\n",
    "df_returns = df[['Daily_Return']].copy()\n",
    "for lag in range(1, 6):\n",
    "    df_returns[f'Return_lag_{lag}'] = df_returns['Daily_Return'].shift(lag)\n",
    "\n",
    "# Add moving averages of returns\n",
    "df_returns['MA_5'] = df_returns['Daily_Return'].shift(1).rolling(window=5).mean()\n",
    "df_returns['MA_10'] = df_returns['Daily_Return'].shift(1).rolling(window=10).mean()\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df_returns.dropna(inplace=True)\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(df_returns) * 0.8)\n",
    "train_returns = df_returns.iloc[:train_size]\n",
    "test_returns = df_returns.iloc[train_size:]\n",
    "\n",
    "# Prepare features\n",
    "return_features = [f'Return_lag_{i}' for i in range(1, 6)] + ['MA_5', 'MA_10']\n",
    "X_train_ret = train_returns[return_features]\n",
    "y_train_ret = train_returns['Daily_Return']\n",
    "X_test_ret = test_returns[return_features]\n",
    "y_test_ret = test_returns['Daily_Return']\n",
    "\n",
    "# Train models on returns\n",
    "lr_model_ret = LinearRegression()\n",
    "lr_model_ret.fit(X_train_ret, y_train_ret)\n",
    "lr_pred_ret = lr_model_ret.predict(X_test_ret)\n",
    "\n",
    "rf_model_ret = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_ret.fit(X_train_ret, y_train_ret)\n",
    "rf_pred_ret = rf_model_ret.predict(X_test_ret)\n",
    "\n",
    "# Evaluate\n",
    "lr_mse_ret = mean_squared_error(y_test_ret, lr_pred_ret)\n",
    "rf_mse_ret = mean_squared_error(y_test_ret, rf_pred_ret)\n",
    "\n",
    "print(f\"Linear Regression on Returns - MSE: {lr_mse_ret:.4f}\")\n",
    "print(f\"Random Forest on Returns - MSE: {rf_mse_ret:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79ac84-b862-4c99-8df0-2518b080f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Convert Return Predictions Back to Price Predictions\n",
    "\n",
    "# Get the last known price\n",
    "last_price = df['Close'].iloc[train_size + len(test_returns) - 1]\n",
    "\n",
    "# Convert return predictions to price predictions\n",
    "lr_price_pred = [last_price]\n",
    "for ret in lr_pred_ret:\n",
    "    lr_price_pred.append(lr_price_pred[-1] * (1 + ret/100))\n",
    "\n",
    "rf_price_pred = [last_price]\n",
    "for ret in rf_pred_ret:\n",
    "    rf_price_pred.append(rf_price_pred[-1] * (1 + ret/100))\n",
    "\n",
    "# Get actual prices for comparison\n",
    "actual_prices = df['Close'].iloc[train_size:train_size+len(test_returns)+1].values\n",
    "\n",
    "# Evaluate price predictions\n",
    "lr_price_mse = mean_squared_error(actual_prices[1:], lr_price_pred[1:])\n",
    "rf_price_mse = mean_squared_error(actual_prices[1:], rf_price_pred[1:])\n",
    "\n",
    "print(f\"Linear Regression (from returns) - Price MSE: {lr_price_mse:.2f}\")\n",
    "print(f\"Random Forest (from returns) - Price MSE: {rf_price_mse:.2f}\")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(test_data.index[:len(actual_prices)], actual_prices, label='Actual', linewidth=2)\n",
    "plt.plot(test_data.index[:len(lr_price_pred[1:])], lr_price_pred[1:], label='Linear Regression (from returns)', alpha=0.7)\n",
    "plt.plot(test_data.index[:len(rf_price_pred[1:])], rf_price_pred[1:], label='Random Forest (from returns)', alpha=0.7)\n",
    "plt.title('Stock Price Forecasting Using Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5d6d2-dac2-448b-88a3-7dfa004349dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cell 21: Compare All Approaches\n",
    "\n",
    "# Create a comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['ARIMA (Original)', 'Linear Regression (Original)', 'Random Forest (Original)',\n",
    "              'Linear Regression (Returns)', 'Random Forest (Returns)'],\n",
    "    'MSE': [arima_mse, lr_mse, rf_mse, lr_price_mse, rf_price_mse],\n",
    "    'Approach': ['Differencing', 'Lagged Features', 'Lagged Features', \n",
    "                 'Returns → Prices', 'Returns → Prices']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df.sort_values('MSE'))\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='MSE', data=comparison_df)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
